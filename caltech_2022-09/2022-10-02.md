# Kubernetes Playground
1. Login to the Kubernetes playground with your Docker account and start a new session:

   * https://labs.play-with-k8s.com/
1. Add a new instance and initialize the kubernetes cluster master node:

   ```
   kubeadm init --apiserver-advertise-address $(hostname -i) --pod-network-cidr 10.5.0.0/16
   ```
1. Initialize the cluster networking:

   ```
   kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter.yaml
   ```
1. Deploy a sample application:

   ```
   kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml
   ```
1. Check the status of the deployment:

   ```
   kubectl get all
   ```
1. As you can see in the logs, the Service is not working. It is because the Type of the Service is Loadbalancer. This type of Service requieres cloud credentials to create a Load Balancer in the Cloud of your choice. The best way to solve this problem is to change the type of the Service. In order to do so, we first download the YAML manifest:

    ```
    curl -O https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml
    ```
1. Now we can modify the Service configuration with the following command:

    ```
    sed -i /LoadBalancer/d nginx-app.yaml
    ```
1. Redeploy the manifest with the changes:

    ```
    kubectl apply -f nginx-app.yaml
    ```
1. Check again the status of the deployment:

    ```
    kubectl get all
    ```
1. Now the Service has been correctly created but there is still an issue: all the Pods are in a Pending state. To troubleshoot the problem we check the events with th e following command:

    ```
    kubectl get ev
    ```
1. The latest event shows that there is a Taint that forbids the deployment of the Pods:

    ```
    0/1 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate
    ```
1. Taints are labels (or marks) applied to the nodes in order to forbid the deployment of containers. By default the master node is tainted in order to secure the cluster. To solve this situation, the easiest way is to create a worker node for the deployment.    
  
3. Add a new instance and join the master node pasting the following command in the newly created instance:

   ```
   kubeadm join 192.168.0.13:6443 --token vz62an.sukbig1y0njsy9db --discovery-token-ca-cert-hash sha256:fc04257351d61322577d551e4a543a488d2a39afc1333cd07839a9a4c2e39b88
   ```
1. Check again the status of the deployment:

   ```
   kubectl get all
   ```
1. Now all the Pods should be correctly running and the Deployment completely Ready. But the application is still not available from outside because the container network is isolated by default. In order to be able to connect to the container network from an external web browser, we need to map a port of the external host network to a port of the internal container network. To do so, we will download again the YAML manifest and modifiy it:

    ```
    rm -f nginx-app.yaml
    
    curl -O https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml

    sed -i s/LoadBalancer/NodePort/ nginx-app.yaml
    ```
    
3. In order to remove the previous deployment run the following command:

   ```
   kubectl delete -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml
   ```
# Docker Swarm production cluster in AWS
1. Use the following template to create the cluster infrastructure in AWS:

    * https://raw.githubusercontent.com/secobau/docker-aws/master/etc/aws/cluster-docker.yaml

1. Connect to first master instance and initialize the Docker Swarm:

    ```
    sudo docker swarm init --advertise-addr 10.168.1.100
    ```
1. Connect to the three worker instances and join the master node
2. Connect to the leader master and generate the token for the manager nodes:

    ```
    sudo docker swarm join-token manager
    ```
1. Connect to the other two master instances and join the master node
2. Check the current members of the cluster:

    ```
    sudo docker node ls
    ```
1. Deploy a sample application (using Node Port 30001):

   1. First download the configuration file:
      ```
      wget https://raw.githubusercontent.com/academiaonline-org/phpinfo/main/src/index.php
      ```
   1. Now create the Docker Compose file for the deployment:
      ```
      tee ${PWD}/docker-swarm-1.yaml 0<<EOF

      # docker run --detach --name phpinfo --network phpinfo-default --restart always --publish 8080 --user nobody:nogroup --volume ${PWD}/index.php:/data/index.php:ro --workdir /data/ index.docker.io/library/php:alpine php -f index.php -S 0.0.0.0:8080
      configs:
        phpinfo-config:
          external: false
          file: index.php
      services:
        phpinfo:
          # command: [ "php","-f","index.php","-S","0.0.0.0:8080" ]
          command:
            - php
            - -f
            - index.php
            - -S
            - 0.0.0.0:8080
          configs:
            - source: phpinfo-config
              target: /data/index.php
              uid: '65534'
              gid: '65534'
              mode: 0400
          deploy:
            placement:
              constraints:
                - "node.role==worker"      
            replicas: 1
          image: index.docker.io/library/php:8.0-alpine
          ports:
            - 30001:8080
          user: nobody:nogroup
          working_dir: /data/
      version: '3.8'

      EOF
      ```
   1. Now deploy the application:
      ```
      sudo docker stack deploy --compose-file docker-swarm-1.yaml PHPINFO-1
      ```
   1. Check the status of the deployment:
      ```
      sudo docker stack services PHPINFO-1
      ```
1. Deploy another version of the same application using a different Node Port (31001):
   1. Create the Docker Compose for the new deployment:

      ```
      tee ${PWD}/docker-swarm-2.yaml 0<<EOF

      # docker run --detach --name phpinfo --network phpinfo-default --restart always --publish 8080 --user nobody:nogroup --volume ${PWD}/index.php:/data/index.php:ro --workdir /data/ index.docker.io/library/php:alpine php -f index.php -S 0.0.0.0:8080
      configs:
        phpinfo-config:
          external: false
          file: index.php
      services:
        phpinfo:
          # command: [ "php","-f","index.php","-S","0.0.0.0:8080" ]
          command:
            - php
            - -f
            - index.php
            - -S
            - 0.0.0.0:8080
          configs:
            - source: phpinfo-config
              target: /data/index.php
              uid: '65534'
              gid: '65534'
              mode: 0400
          deploy:
            placement:
              constraints:
                - "node.role==worker"      
            replicas: 1
          image: index.docker.io/library/php:8.1-alpine
          ports:
            - 31001:8080
          user: nobody:nogroup
          working_dir: /data/
      version: '3.8'

      EOF
      ```
   1. Deploy the new version:

      ```
      sudo docker stack deploy --compose-file docker-swarm-2.yaml PHPINFO-2
      ```
   1. Check the status of the new deployment:

      ```
      sudo docker stack services PHPINFO-2
      ```
1. The load balancer created in AWS with the previous template contains two different listeners to access both deployments:
   1. The first listener is listening on port 80 and forwarding the traffic to Node Port 30001 (that is pointing to the first deployment)
   2. The second listener is listening on port 8080 and forwarding the traffic to the Node Port 31001 (that is pointing to the second deployment)   
# Install Mirantis Container Runtime for Ubuntu
The following instructions have been extracted from this documentation:
   * https://docs.mirantis.com/mcr/20.10/install/mcr-linux/ubuntu.html
1. Uninstall old versions

   ```
   sudo apt-get --yes remove docker docker-engine docker-ce docker-ce-cli docker.io
   ```
1. Update the apt package index

   ```
   sudo apt-get update
   ```
1. Install packages to allow apt to use a repository over HTTPS

   ```
   Install packages to allow apt to use a repository over HTTPS
   ```
1. Temporarily store https://repos.mirantis.com in an environment variable. This variable assignment does not persist when the session ends

   ```
   DOCKER_EE_URL="https://repos.mirantis.com"
   ```
1. Temporarily add a $DOCKER_EE_VERSION variable into your environment

   ```
   DOCKER_EE_VERSION=20.10
   ```
1. Add Docker’s official GPG key using your customer Mirantis Container Runtime repository URL

   ```
   Add Docker’s official GPG key using your customer Mirantis Container Runtime repository URL
   ```
1. Set up the stable repository, using the following command as-is (which works due to the variable set up earlier in the process)

   ```
   sudo add-apt-repository "deb [arch=$(dpkg --print-architecture)] $DOCKER_EE_URL/ubuntu $(lsb_release -cs) stable-$DOCKER_EE_VERSION"
   ```
1. Update the apt package index
   ```
   sudo apt-get update
   ```
1. Install the latest version of Mirantis Container Runtime and containerd, or go to the next step to install a specific version. Any existing installation of MCR is replaced

   ```
   sudo apt-get --yes install docker-ee docker-ee-cli containerd.io
   ```
# Install the MKE image   
The following instructions have been extracted from this documentation:
   * https://docs.mirantis.com/mke/3.5/install/install-mke-image.html
1. Install MKE

   ```
   sudo docker run --interactive --name ucp --rm --tty --volume /var/run/docker.sock:/var/run/docker.sock mirantis/ucp:3.5.5 install --host-address $( hostname --ip-address ) --interactive --force-minimums
   ```
     
